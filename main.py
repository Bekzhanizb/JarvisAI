import os
import json
import wave
import tempfile
import numpy as np
import sounddevice as sd
from vosk import Model, KaldiRecognizer
from gtts import gTTS
from openai import OpenAI
from dotenv import load_dotenv
import psycopg2

# ====== Parameters ======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

DB_CONFIG = {
    "dbname": "shyraq_db",
    "user": "postgres",
    "password": "1234",
    "host": "localhost",
    "port": 5432
}

# ====== Initializing ======
client = OpenAI(api_key=OPENAI_API_KEY)
conn = psycopg2.connect(**DB_CONFIG)
cursor = conn.cursor()

cursor.execute("""
CREATE TABLE IF NOT EXISTS dialog_history (
    id SERIAL PRIMARY KEY,
    role TEXT,
    content TEXT
);
""")
conn.commit()

# ====== Kazakh Speech Model (Vosk) ======
MODEL_PATH = "vosk-model-small-kz-0.42"
print("üîÑ Vosk –º–æ–¥–µ–ª—ñ–Ω –∂“Ø–∫—Ç–µ—É...")
model = Model(MODEL_PATH)
print("‚úÖ “ö–∞–∑–∞“õ —Ç—ñ–ª—ñ –º–æ–¥–µ–ª—ñ —Å”ô—Ç—Ç—ñ –∂“Ø–∫—Ç–µ–ª–¥—ñ!")

# ====== DB functions ======
def save_message(role, content):
    cursor.execute("INSERT INTO dialog_history (role, content) VALUES (%s, %s)", (role, content))
    conn.commit()

# ====== Recording ======
def record_voice(duration=5, fs=44100):
    print("üéôÔ∏è –î—ã–±—ã—Å –∂–∞–∑—ã–ª—É–¥–∞...")
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype=np.int16)
    sd.wait()
    filename = tempfile.mktemp(prefix="voice_", suffix=".wav")
    with wave.open(filename, "wb") as f:
        f.setnchannels(1)
        f.setsampwidth(2)
        f.setframerate(fs)
        f.writeframes(audio.tobytes())
    return filename

# ====== Transcribing (Vosk) ======
def transcribe_audio_vosk(filename):
    wf = wave.open(filename, "rb")
    rec = KaldiRecognizer(model, wf.getframerate())

    text_result = ""
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            text_result += result.get("text", "") + " "
    final = json.loads(rec.FinalResult())
    text_result += final.get("text", "")
    return text_result.strip()

# ====== Voice the text ======
def speak_kz(text):
    print("üîä Jarvis —Å”©–π–ª–µ–ø –∂–∞—Ç—ã—Ä (OpenAI TTS)...")
    speech = tempfile.mktemp(suffix=".wav")
    with client.audio.speech.with_streaming_response.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text
    ) as response:
        response.stream_to_file(speech)

    os.system(f"mpg123 {speech}")


# ====== Jarvis replying ======
def chat_with_jarvis(prompt):
    save_message("user", prompt)

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "–°–µ–Ω Jarvis –µ—Å—ñ–º–¥—ñ “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ —Å”©–π–ª–µ–π—Ç—ñ–Ω –∂–∞—Å–∞–Ω–¥—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—ñ—Å—ñ“£. –ü–∞–π–¥–∞–ª–∞–Ω—É—à—ã“ì–∞ —Ç–µ–∫ “õ–∞–∑–∞“õ—à–∞ –∂–∞—É–∞–ø –±–µ—Ä. –ï–≥–µ—Ä —Å“±—Ä–∞“õ –∞“ì—ã–ª—à—ã–Ω—à–∞ –±–æ–ª—Å–∞, –æ–Ω—ã “õ–∞–∑–∞“õ—à–∞ –∞—É–¥–∞—Ä—ã–ø —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä."},
            {"role": "user", "content": prompt}
        ]
    )

    answer = response.choices[0].message.content
    save_message("assistant", answer)
    return answer

# ====== Main loop ======
print("ü§ñ Jarvis v0.2 (“ö–∞–∑–∞“õ—à–∞) —ñ—Å–∫–µ “õ–æ—Å—ã–ª–¥—ã!")
print("–ê–π—Ç“õ—ã“£—ã–∑ –∫–µ–ª–≥–µ–Ω–¥—ñ –∞–π—Ç—ã“£—ã–∑ (–Ω–µ–º–µ—Å–µ '—à—ã“ì—É' –¥–µ–ø –∞—è“õ—Ç–∞“£—ã–∑).")

while True:
    filename = record_voice(duration=5)
    text = transcribe_audio_vosk(filename)

    if not text:
        print("‚ùå –°”©–∑ —Ç–∞–Ω—ã–ª–º–∞–¥—ã, “õ–∞–π—Ç–∞–¥–∞–Ω –∞–π—Ç—ã“£—ã–∑.")
        continue

    if text.lower() in ["—à—ã“ì—É", "exit", "stop"]:
        print("Jarvis: –ö”©—Ä—ñ—Å–∫–µ–Ω—à–µ —Å–∞—É –±–æ–ª! üëã")
        break

    print("üßç‚Äç‚ôÇÔ∏è –°—ñ–∑:", text)
    reply = chat_with_jarvis(text)
    print("ü§ñ Jarvis:", reply)
    speak_kz(reply)
